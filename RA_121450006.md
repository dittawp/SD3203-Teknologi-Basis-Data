## TUGAS PERTEMUAN 9 TEKNOLOGI BASIS DATA

Nama  : Ditta Winanda Putri \
NIM   : 121450006 \
Kelas : RA

**Kumpulan Data Untuk di Proses**
"""

import numpy as np
import pickle
from pathlib import Path

# Path to the unzipped CIFAR data
data_dir = Path("C:/Users/HP/Downloads/cifar-10-python/cifar-10-batches-py")

# Unpickle function provided by the CIFAR hosts
def unpickle(file):
    with open(file, "rb") as fo:
        dict = pickle.load(fo, encoding="bytes")
    return dict

images, labels = [], []
for batch in data_dir.glob("data_batch_*"):
    batch_data = unpickle(batch)
    for i, flat_im in enumerate(batch_data[b"data"]):
        im_channels = []
        # Each image is flattened, with channels in order of R, G, B
        for j in range(3):
            im_channels.append(
                flat_im[j * 1024 : (j + 1) * 1024].reshape((32, 32))
            )
        # Reconstruct the original image
        images.append(np.dstack((im_channels)))
        # Save the label
        labels.append(batch_data[b"labels"][i])

print("Loaded CIFAR-10 training set:")
print(f" - np.shape(images)     {np.shape(images)}")
print(f" - np.shape(labels)     {np.shape(labels)}")

"""Pertama, kita membuat fungsi sederhana untuk membuka file yang disimpan dalam format khusus di mana kita menyimpan data CIFAR-10. Dalam kode di atas, kita membuka setiap file dalam direktori data. Jika nama file dimulai dengan "data_batch", itu kemungkinan adalah file batch yang berisi gambar dan label. Kita membuka file tersebut, ambil data gambar dan labelnya, dan kemudian ubah formatnya menjadi sesuatu yang lebih mudah dipahami. Setelah semua batch telah diproses, kita periksa berapa jumlah total gambar dan label yang telah kita muat."""

from pathlib import Path

disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")

"""Setiap objek ini adalah alamat yang menyimpan informasi tentang di mana direktori tertentu berada: disk_dir adalah tempat di mana kita menemukan direktori "data/disk/", lmdb_dir adalah tempat di mana kita menemukan direktori "data/lmdb/", dan hdf5_dir adalah tempat di mana kita menemukan direktori "data/hdf5/". Dengan objek-objek ini, kita bisa dengan mudah melakukan berbagai operasi seperti mengelola file, membuat direktori baru, atau memeriksa apakah suatu file ada di sana."""

disk_dir.mkdir(parents=True, exist_ok=True)
lmdb_dir.mkdir(parents=True, exist_ok=True)
hdf5_dir.mkdir(parents=True, exist_ok=True)

"""Kode di atas menggunakan metode `mkdir()` pada objek `Path` untuk menciptakan tiga direktori yang dibutuhkan: `disk_dir`, `lmdb_dir`, dan `hdf5_dir`. Dengan menambahkan argumen `parents=True`, kode tersebut juga membuat direktori induk jika diperlukan, dan `exist_ok=True` memastikan bahwa tidak akan ada masalah jika direktori tersebut sudah ada sebelumnya. Dengan cara ini, kita membuat tiga direktori yang diperlukan dengan efisien dalam proyek kita."""

from PIL import Image
import csv

def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")

    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label])

"""Penjelasan kode diatas adalah sebuah fungsi Python yang dirancang untuk menyimpan gambar dan label ke dalam direktori yang sudah dibuat sebelumnya menggunakan objek `Path` yang telah Anda definisikan sebelumnya. Fungsi `store_single_disk` menerima tiga argumen: gambar (sebagai array dengan dimensi 32x32x3), ID unik gambar (sebagai integer), dan label gambar. Pertama, gambar disimpan sebagai file .png di dalam direktori `disk_dir` dengan nama file yang sesuai dengan ID gambar. Selanjutnya, label disimpan ke dalam file .csv yang juga ditempatkan di dalam direktori yang sama dengan nama file yang berisi ID gambar tersebut. Dengan menggunakan fungsi ini, Anda dapat dengan mudah menyimpan gambar beserta labelnya ke dalam struktur direktori yang sudah Anda siapkan sebelumnya."""

class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary
        # for this dataset, but some datasets may include images of
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]

        self.image = image.tobytes()
        self.label = label

    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)

"""Pertama, kita menyimpan dimensi gambar (jumlah saluran warna dan ukuran gambar) karena kadang-kadang kita butuh informasi ini untuk merekonstruksi gambar. Meskipun untuk dataset CIFAR-10 ini informasi ini tidak terlalu penting karena semua gambarnya memiliki ukuran yang sama. \
Kemudian, kita mengubah gambar menjadi format byte agar bisa disimpan dalam bentuk byte. Ini akan mempermudah proses penyimpanan dan pengambilan gambar. \
Terakhir, kita menyimpan label untuk gambar tersebut.
"""

import lmdb
import pickle

def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = image.nbytes * 10

    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)

    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

"""Fungsi `store_single_lmdb` digunakan untuk menyimpan sebuah gambar ke dalam sebuah basis data berbasis LMDB. Fungsi ini menerima tiga argumen: gambar itu sendiri (dalam bentuk array numpy dengan ukuran 32x32x3), ID unik gambar, dan label gambar tersebut.

Di dalam fungsi, kita menghitung ukuran peta (map) yang diperlukan untuk menyimpan gambar tersebut dalam basis data. Ini dilakukan dengan mengalikan ukuran gambar dalam byte dengan 10, sehingga kita memiliki ruang yang cukup untuk menyimpan beberapa gambar.

Kemudian, kita membuat sebuah lingkungan LMDB baru menggunakan fungsi `lmdb.open()`. Kita memberikan nama untuk lingkungan LMDB ini, yang dalam hal ini adalah "single_lmdb", dan juga menentukan ukuran peta (map) yang telah kita hitung sebelumnya.

Setelah itu, kita mulai transaksi tulis baru menggunakan `with env.begin(write=True) as txn:`. Di dalam transaksi ini, kita membuat pasangan kunci-nilai untuk disimpan dalam basis data. Kunci adalah ID gambar yang telah diubah menjadi string, sedangkan nilainya adalah objek `CIFAR_Image` yang telah kita buat sebelumnya. Objek ini berisi gambar dan labelnya.

Akhirnya, setelah semua data dimasukkan, kita tutup lingkungan LMDB menggunakan `env.close()`.

Analisis singkat : Kode ini efektif dalam menyimpan gambar-gambar CIFAR-10 ke dalam basis data LMDB. Penggunaan transaksi tulis memastikan bahwa data disimpan secara konsisten dan aman. Dengan menggunakan struktur data seperti LMDB, kita dapat dengan efisien menyimpan dan mengakses gambar-gambar ini untuk keperluan pemrosesan data selanjutnya.
"""

import h5py

def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close()

"""Fungsi `store_single_hdf5` digunakan untuk menyimpan sebuah gambar ke dalam sebuah file HDF5. Fungsi ini menerima tiga argumen: gambar (dalam bentuk array numpy dengan ukuran 32x32x3), ID unik gambar, dan label gambar tersebut.

Dalam fungsi, pertama-tama kita membuat sebuah file HDF5 baru menggunakan `h5py.File()`. Nama file tersebut disesuaikan dengan ID gambar yang diberikan.

Selanjutnya, kita membuat sebuah dataset di dalam file tersebut menggunakan `file.create_dataset()`. Dataset ini akan menyimpan gambar. Kita juga membuat dataset lain yang akan menyimpan label gambar. Kedua dataset tersebut diinisialisasi dengan data gambar dan label yang diberikan.

Akhirnya, setelah semua data dimasukkan, kita menutup file HDF5 menggunakan `file.close()`.

Dengan menggunakan struktur file HDF5, kita dapat dengan mudah menyimpan dan mengakses gambar-gambar CIFAR-10 bersama dengan labelnya untuk keperluan pemrosesan data selanjutnya.
"""

_store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
)

"""Baris kode di atas membuat sebuah kamus yang disebut `_store_single_funcs`. Kamus ini memiliki tiga kunci: "disk", "lmdb", dan "hdf5". Setiap kunci memiliki nilai berupa fungsi yang sesuai untuk menyimpan sebuah gambar.

- Fungsi `store_single_disk` digunakan untuk menyimpan gambar ke dalam direktori menggunakan format disk.
- Fungsi `store_single_lmdb` digunakan untuk menyimpan gambar ke dalam basis data LMDB.
- Fungsi `store_single_hdf5` digunakan untuk menyimpan gambar ke dalam file HDF5.

Dengan memiliki kamus ini, kita dapat dengan mudah memilih metode penyimpanan yang sesuai tergantung pada kebutuhan atau preferensi kita. Misalnya, jika kita ingin menyimpan gambar ke dalam direktori, kita dapat menggunakan `_store_single_funcs['disk']`. Sedangkan jika kita ingin menyimpan gambar ke dalam basis data LMDB, kita dapat menggunakan `_store_single_funcs['lmdb']`, dan begitu seterusnya.
"""

from timeit import timeit

store_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")

"""Kode di atas melakukan pengukuran waktu eksekusi untuk setiap metode penyimpanan gambar yang didefinisikan sebelumnya. Pengukuran dilakukan untuk satu gambar pertama dari dataset CIFAR-10, dan hasilnya dicatat dalam kamus `store_single_timings`.

Untuk setiap metode ("disk", "lmdb", dan "hdf5"), pengukuran waktu dilakukan dengan menggunakan fungsi `timeit()`. Fungsi ini mengukur waktu eksekusi dari ekspresi yang diberikan dalam parameter pertama. Ekspresi tersebut adalah pemanggilan fungsi yang sesuai untuk metode penyimpanan gambar, yaitu `_store_single_funcs[method](image, 0, label)`.

Fungsi `timeit()` dieksekusi sekali saja (`number=1`) dengan menggunakan gambar pertama dari dataset CIFAR-10 (`image=images[0]`) dan label yang sesuai (`label=labels[0]`). Fungsi `globals()` digunakan untuk memberikan lingkup global ke dalam eksekusi waktu, sehingga semua variabel yang diperlukan (seperti `_store_single_funcs`, `images`, `labels`) dapat diakses di dalam ekspresi yang diukur.

Hasil pengukuran waktu untuk setiap metode disimpan dalam kamus `store_single_timings`, dan juga dicetak untuk ditampilkan kepada pengguna.
"""

def store_many_disk(images, labels):
    """ Stores an array of images to disk
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Save all the images one by one
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")

    # Save all the labels to the csv file
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # This typically would be more than just one value per row
            writer.writerow([label])

def store_many_lmdb(images, labels):
    """ Stores an array of images to LMDB.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    map_size = num_images * images[0].nbytes * 10

    # Create a new LMDB DB for all the images
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)

    # Same as before — but let's write all the images in a single transaction
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # All key-value pairs need to be Strings
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

def store_many_hdf5(images, labels):
    """ Stores an array of images to HDF5.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close()

"""Fungsi-fungsi di atas adalah untuk menyimpan banyak gambar ke dalam berbagai format penyimpanan yang telah dijelaskan sebelumnya: `store_many_disk`, `store_many_lmdb`, dan `store_many_hdf5`.

- Fungsi `store_many_disk` menyimpan sebuah array gambar ke dalam format disk, dengan setiap gambar disimpan sebagai file .png dan labelnya disimpan dalam file .csv terpisah.
- Fungsi `store_many_lmdb` menyimpan array gambar ke dalam basis data LMDB, dengan setiap gambar dan labelnya disimpan dalam satu transaksi tulis.
- Fungsi `store_many_hdf5` menyimpan array gambar ke dalam file HDF5, dengan dataset yang berisi gambar dan label.

Semua fungsi memiliki parameter `images` yang merupakan array gambar dengan dimensi (N, 32, 32, 3) dan `labels` yang merupakan array label dengan dimensi (N, 1), di mana N adalah jumlah total gambar.

Fungsi-fungsi ini berguna ketika Anda ingin menyimpan banyak gambar sekaligus ke dalam struktur penyimpanan yang sesuai. Misalnya, jika Anda memiliki dataset CIFAR-10 yang besar, Anda dapat menggunakan fungsi-fungsi ini untuk menyimpan seluruh dataset ke dalam format yang dapat diakses kembali dengan mudah nanti.
"""

cutoffs = [10, 100, 1000, 10000, 100000]

# Let's double our images so that we have 100,000
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)

# Make sure you actually have 100,000 images and labels
print(np.shape(images))
print(np.shape(labels))

"""Kode di atas menginisialisasi sebuah list `cutoffs` yang berisi beberapa angka yang disebut "cutoffs". Selanjutnya, kode tersebut menggandakan jumlah gambar dan label yang tersedia sehingga kita memiliki total 100.000 gambar.

Fungsi `np.concatenate()` digunakan untuk menggandakan array `images` dan `labels` dengan cara menggabungkan array itu sendiri dengan dirinya sendiri (dilakukan dengan parameter `axis=0`). Hasilnya adalah kita mendapatkan dua kali lipat jumlah gambar dan label yang ada sebelumnya.

Kemudian, kode mencetak bentuk dari array `images` dan `labels` setelah penggandaan dilakukan untuk memastikan bahwa kita benar-benar memiliki 100.000 gambar dan label. Ini akan memverifikasi bahwa operasi penggandaan telah berhasil dilakukan.
"""

_store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)

from timeit import timeit

store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}")

"""Hasil output tersebut menunjukkan waktu yang dibutuhkan (dalam detik) oleh setiap metode (`disk`, `lmdb`, `hdf5`) untuk menyimpan sejumlah gambar dan label yang berbeda-beda berdasarkan nilai cutoff yang ditentukan sebelumnya (10, 100, 1000, 10000, 100000).

Pertama, pada saat nilai cutoff adalah 10, waktu yang dibutuhkan untuk metode `disk` adalah sekitar 0.043 detik, untuk metode `lmdb` adalah sekitar 0.013 detik, dan untuk metode `hdf5` adalah sekitar 0.054 detik.

Kedua, ketika nilai cutoff adalah 100, waktu yang dibutuhkan untuk metode `disk` naik menjadi sekitar 0.167 detik, sementara metode `lmdb` menjadi sekitar 0.005 detik, dan metode `hdf5` menjadi sekitar 0.002 detik.

Ketiga, ketika nilai cutoff terus bertambah hingga mencapai 100000, waktu yang dibutuhkan juga meningkat secara signifikan. Metode `disk` membutuhkan waktu sekitar 12.147 detik, metode `lmdb` membutuhkan waktu sekitar 0.297 detik, dan metode `hdf5` membutuhkan waktu sekitar 0.026 detik.

Dari hasil ini, dapat dilihat bahwa performa relatif dari masing-masing metode berbeda tergantung pada jumlah data yang disimpan. Metode `lmdb` cenderung memiliki waktu eksekusi yang lebih singkat dibandingkan dengan `disk` dan `hdf5`, terutama saat jumlah data yang disimpan semakin besar. Sedangkan `disk` cenderung membutuhkan waktu lebih lama karena operasi I/O pada disk, sedangkan `hdf5` memiliki waktu eksekusi yang stabil tergantung pada jumlah data yang disimpan.
"""

import matplotlib.pyplot as plt

def plot_with_legend(
    x_range, y_data, legend_labels, x_label, y_label, title, log=False
):
    """ Displays a single plot with multiple datasets and matching legends.
        Parameters:
        --------------
        x_range         list of lists containing x data
        y_data          list of lists containing y values
        legend_labels   list of string legend labels
        x_label         x axis label
        y_label         y axis label
    """
    plt.style.use("seaborn-whitegrid")
    plt.figure(figsize=(10, 7))

    if len(y_data) != len(legend_labels):
        raise TypeError(
            "Error: number of data sets does not match number of labels."
        )

    all_plots = []
    for data, label in zip(y_data, legend_labels):
        if log:
            temp, = plt.loglog(x_range, data, label=label)
        else:
            temp, = plt.plot(x_range, data, label=label)
        all_plots.append(temp)

    plt.title(title)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.legend(handles=all_plots)
    plt.show()

# Getting the store timings data to display
disk_x = store_many_timings["disk"]
lmdb_x = store_many_timings["lmdb"]
hdf5_x = store_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Storage time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Log storage time",
    log=True,
)

def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))

    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])

    return image, label

"""Fungsi `read_single_disk` ini digunakan untuk membaca sebuah gambar dan labelnya yang telah disimpan dalam disk. Gambar dibaca menggunakan `Image.open` dari modul PIL dan kemudian diubah menjadi array numpy. Labelnya dibaca dari file CSV yang sesuai dengan ID gambar.

Setelah membaca gambar dan labelnya, fungsi ini mengembalikan gambar dalam bentuk array dengan dimensi (32, 32, 3) dan labelnya dalam bentuk integer. Dengan demikian, fungsi ini memungkinkan untuk membaca kembali data gambar dan label yang telah disimpan dalam format yang telah ditentukan sebelumnya di dalam disk.
"""

def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()

    return image, label

"""Kode `read_single_lmdb` berfungsi untuk membaca sebuah gambar dan label yang tersimpan dalam basis data LMDB. Fungsi ini menerima satu argumen yaitu `image_id`, yang merupakan ID unik untuk gambar yang akan dibaca.

Pertama, lingkungan LMDB dibuka dengan mode hanya baca (readonly=True) menggunakan `lmdb.open`. Selanjutnya, transaksi baca baru dimulai dengan `env.begin()`. Key yang digunakan untuk mengambil data harus diencode dengan metode yang sama saat menyimpan data.

Kemudian, data gambar diambil dari basis data LMDB dengan menggunakan `txn.get`. Data tersebut di-decode menggunakan `pickle.loads` karena data gambar disimpan sebagai objek CIFAR_Image saat disimpan.

Setelah data diambil, gambar direkonstruksi menggunakan metode `get_image()` dari objek CIFAR_Image, dan labelnya diambil langsung dari atribut label pada objek tersebut.

Terakhir, lingkungan LMDB ditutup dan gambar beserta labelnya dikembalikan sebagai output dari fungsi. Dengan fungsi ini, Anda dapat dengan mudah membaca gambar dan label dari basis data LMDB berdasarkan ID unik gambar yang diberikan.
"""

def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")

    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))

    return image, label

"""Fungsi `read_single_hdf5` digunakan untuk membaca sebuah gambar dan label yang tersimpan dalam file HDF5. Fungsi ini menerima satu argumen yaitu `image_id`, yang merupakan ID unik untuk gambar yang akan dibaca.

Pertama, file HDF5 dibuka dengan mode baca dan tulis (r+ mode) menggunakan `h5py.File`. Kemudian, gambar dibaca dari dataset "image" dalam file HDF5 dan diubah menjadi array numpy dengan tipe data `uint8` (unsigned integer 8-bit). Selanjutnya, label dibaca dari dataset "meta" dan juga diubah menjadi integer dengan tipe data `uint8`.

Setelah membaca data gambar dan label, file HDF5 ditutup dan gambar beserta labelnya dikembalikan sebagai output dari fungsi.

Dengan fungsi ini, Anda dapat dengan mudah membaca gambar dan label dari file HDF5 berdasarkan ID unik gambar yang diberikan.
"""

_read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
)

"""Kode `_read_single_funcs` membuat sebuah kamus yang berisi tiga fungsi: `read_single_disk`, `read_single_lmdb`, dan `read_single_hdf5`, masing-masing terkait dengan metode membaca data dari lokasi penyimpanan yang berbeda (`disk`, `lmdb`, dan `hdf5`). Hal ini memungkinkan penggunaan kamus ini untuk memilih metode membaca yang sesuai dengan kebutuhan aplikasi, dengan cukup memanggil fungsi yang sesuai dengan kunci yang diinginkan (seperti `'disk'` untuk membaca dari disk, `'lmdb'` untuk membaca dari LMDB, dan `'hdf5'` untuk membaca dari HDF5). Dengan cara ini, fleksibilitas dalam memilih cara membaca data dapat diterapkan dengan mudah dalam program Anda."""

from timeit import timeit

read_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs[method](0)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")

"""Hasil output tersebut menunjukkan waktu yang dibutuhkan (dalam detik) oleh masing-masing metode (`disk`, `lmdb`, `hdf5`) untuk membaca sebuah gambar dan label dari lokasi penyimpanan yang berbeda.

Dari hasil tersebut, dapat disimpulkan bahwa metode `hdf5` adalah yang paling cepat dalam hal waktu membaca data, diikuti oleh metode `lmdb`, dan metode `disk` merupakan yang memakan waktu paling lama di antara ketiganya. Informasi ini berguna untuk mengevaluasi performa relatif dari berbagai metode membaca data dan memilih yang paling sesuai berdasarkan kebutuhan aplikasi.
"""

def read_many_disk(num_images):
    """ Reads image from disk.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Loop over all IDs and read each image in one by one
    for image_id in range(num_images):
        images.append(np.array(Image.open(disk_dir / f"{image_id}.png")))

    with open(disk_dir / f"{num_images}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for row in reader:
            labels.append(int(row[0]))
    return images, labels

def read_many_lmdb(num_images):
    """ Reads image from LMDB.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Read all images in one single transaction, with one lock
        # We could split this up into multiple transactions if needed
        for image_id in range(num_images):
            data = txn.get(f"{image_id:08}".encode("ascii"))
            # Remember that it's a CIFAR_Image object
            # that is stored as the value
            cifar_image = pickle.loads(data)
            # Retrieve the relevant bits
            images.append(cifar_image.get_image())
            labels.append(cifar_image.label)
    env.close()
    return images, labels

def read_many_hdf5(num_images):
    """ Reads image from HDF5.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "r+")

    images = np.array(file["/images"]).astype("uint8")
    labels = np.array(file["/meta"]).astype("uint8")

    return images, labels

_read_many_funcs = dict(
    disk=read_many_disk, lmdb=read_many_lmdb, hdf5=read_many_hdf5
)

"""Fungsi-fungsi di atas adalah untuk membaca banyak gambar dari berbagai format penyimpanan yang telah dijelaskan sebelumnya: `read_many_disk`, `read_many_lmdb`, dan `read_many_hdf5`.

- Fungsi `read_many_disk` digunakan untuk membaca gambar-gambar dari penyimpanan disk. Fungsi ini membaca gambar-gambar dari file .png dan label dari file .csv terpisah.
- Fungsi `read_many_lmdb` digunakan untuk membaca gambar-gambar dari basis data LMDB. Fungsi ini membaca gambar-gambar dan label dari basis data LMDB yang sesuai.
- Fungsi `read_many_hdf5` digunakan untuk membaca gambar-gambar dari file HDF5. Fungsi ini membaca gambar-gambar dan label dari file HDF5 yang sesuai.

Semua fungsi memiliki parameter `num_images` yang menentukan jumlah gambar yang akan dibaca.

Kamus `_read_many_funcs` menyimpan referensi ke fungsi-fungsi ini berdasarkan format penyimpanan gambar. Dengan memiliki kamus ini, kita dapat dengan mudah memilih metode pembacaan yang sesuai tergantung pada format penyimpanan gambar yang digunakan. Misalnya, jika kita ingin membaca gambar-gambar dari penyimpanan LMDB, kita dapat menggunakan `_read_many_funcs['lmdb']`.
"""

from timeit import timeit

read_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_read_many_funcs[method](num_images)",
            setup="num_images=cutoff",
            number=1,
            globals=globals(),
        )
        read_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, No. images: {cutoff}, Time usage: {t}")

"""Kode di atas melakukan pengukuran waktu eksekusi untuk membaca banyak gambar dari berbagai format penyimpanan yang telah dijelaskan sebelumnya: disk, LMDB, dan HDF5. Pengukuran waktu dilakukan untuk jumlah gambar tertentu (yang ditentukan oleh `cutoffs`) untuk setiap metode penyimpanan.

Kode tersebut menggunakan loop bersarang untuk melakukan pengukuran waktu untuk setiap kombinasi jumlah gambar (`cutoffs`) dan metode penyimpanan (`disk`, `lmdb`, `hdf5`).

Fungsi `timeit()` digunakan untuk mengukur waktu eksekusi dari ekspresi yang diberikan dalam parameter pertama. Ekspresi tersebut adalah pemanggilan fungsi yang sesuai untuk metode pembacaan gambar (`_read_many_funcs[method](num_images)`).

Pada setiap iterasi, pengukuran waktu dilakukan sekali (`number=1`) untuk jumlah gambar tertentu yang ditentukan oleh `cutoff`. Variabel `num_images` diatur ke nilai `cutoff` menggunakan setup string `setup="num_images=cutoff"`. Variabel `method` juga diambil dari iterasi loop saat ini.

Hasil pengukuran waktu untuk setiap metode disimpan dalam kamus `read_many_timings`, dengan kunci sesuai dengan metode penyimpanan. Setiap waktu yang diukur untuk jumlah gambar tertentu juga dicetak untuk ditampilkan kepada pengguna.
"""